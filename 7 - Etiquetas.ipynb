{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "df = pd.read_excel('caracteristicas.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de la variable clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descripcion = df['clase'].describe()\n",
    "\n",
    "frecuencia_valores = df['clase'].value_counts()\n",
    "\n",
    "# Imprimir la descripcion general de 'clase'\n",
    "print(\"Descripcion general de la columna 'clase':\")\n",
    "print(descripcion)\n",
    "\n",
    "\n",
    "# Imprimir la frecuencia de cada valor unico en 'clase'\n",
    "print(\"Frecuencia de cada valor unico en la columna 'clase':\")\n",
    "print(frecuencia_valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos = df['clase'].unique().tolist()\n",
    "len(unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo preentrenado de Word2Vec\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Convertir las palabras en embeddings\n",
    "word_vectors = []\n",
    "valid_words = []\n",
    "for word in unicos:\n",
    "    if word in model:\n",
    "        word_vectors.append(model[word])\n",
    "        valid_words.append(word)\n",
    "word_vectors = np.array(word_vectors)\n",
    "\n",
    "len(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar las veces que se repite cada palabra en la columna clase\n",
    "cont = defaultdict(int)\n",
    "for palabra in df['clase']:\n",
    "    cont[palabra] += 1\n",
    "\n",
    "print(\"Conteo de las veces que se repite cada palabra en la columna 'clase':\")\n",
    "for p, contar in cont.items():\n",
    "    print(f\"{p}: {contar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupación semántica de etiquetas con K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el numero de clusteres (se probo con 5, 10, 20)\n",
    "num_clusters = 10\n",
    "\n",
    "# Aplicar K-Means a los vectores de las palabras\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(word_vectors)\n",
    "\n",
    "# Agrupar palabras por sus etiquetas de cluster\n",
    "clusters = defaultdict(list)\n",
    "for word, cluster_id in zip(valid_words, kmeans.labels_):\n",
    "    clusters[cluster_id].append(word)\n",
    "\n",
    "# Preparar los datos para escribir en el archivo Excel\n",
    "data = []\n",
    "for cluster_id, words in clusters.items():\n",
    "    for word in words:\n",
    "        data.append({'Cluster': cluster_id, 'Word': word, 'Frequency': cont[word]})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('clusters_10.xlsx', index=False)\n",
    "\n",
    "print(f'Clusters y palabras guardados en clusters_10.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducir la dimensionalidad de los embeddings a 2D usando t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "word_vectors_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# Identificar palabras representativas de cada cluster (cercanas al centroide)\n",
    "representative_words = {}\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "    cluster_vectors = word_vectors[cluster_indices]\n",
    "    centroid = kmeans.cluster_centers_[cluster_id]\n",
    "    closest_word_index = np.argmin(np.linalg.norm(cluster_vectors - centroid, axis=1))\n",
    "    representative_words[cluster_id] = valid_words[cluster_indices[closest_word_index]]\n",
    "\n",
    "# Mostrar los embeddings y los clusteres\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, num_clusters))\n",
    "\n",
    "for i, word in enumerate(valid_words):\n",
    "    cluster_id = kmeans.labels_[i]\n",
    "    plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1], color=colors[cluster_id])\n",
    "\n",
    "# Mostrar palabras representativas\n",
    "for cluster_id, representative_word in representative_words.items():\n",
    "    representative_index = valid_words.index(representative_word)\n",
    "    plt.scatter(word_vectors_2d[representative_index, 0], word_vectors_2d[representative_index, 1], \n",
    "                color=colors[cluster_id], edgecolor='black', linewidth=2, s=100, label=f'Cluster {cluster_id}: {representative_word}')\n",
    "    plt.text(word_vectors_2d[representative_index, 0] + 0.1, word_vectors_2d[representative_index, 1], representative_word, fontsize=12)\n",
    "\n",
    "# Leyenda con etiquetas de colores\n",
    "legend_elements = []\n",
    "for cluster_id in range(num_clusters):\n",
    "    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {cluster_id}', \n",
    "                                      markerfacecolor=colors[cluster_id], markersize=10))\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper right', fontsize='large', bbox_to_anchor=(1.2, 1))\n",
    "plt.title('Clustering de Palabras usando Word2Vec y K-Means')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPCIÓN 1. Mega-etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_excel('clusters_10.xlsx')\n",
    "info_post_df = pd.read_excel('info_post.xlsx')\n",
    "caracteristicas_df = pd.read_excel('caracteristicas.xlsx')\n",
    "\n",
    "# Definir las nuevas columnas\n",
    "new_columns = ['transporte', 'ropa', 'comida', 'mascota', 'varios', 'instrumentos musicales', 'animales', 'objetos', 'alimentos', 'hospital']\n",
    "for col in new_columns:\n",
    "    info_post_df[col] = 0\n",
    "\n",
    "# Crear un diccionario para mapear las clases a sus clusters\n",
    "class_to_cluster = dict(zip(clusters_df['Word'], clusters_df['Cluster']))\n",
    "\n",
    "# Mapeo de cluster_id a nueva columna\n",
    "cluster_to_column = {\n",
    "    0: 'transporte',\n",
    "    1: 'ropa',\n",
    "    2: 'comida',\n",
    "    3: 'perro/gato',\n",
    "    4: 'varios',\n",
    "    5: 'instrumentos musicales',\n",
    "    6: 'animales',\n",
    "    7: 'objetos',\n",
    "    8: 'alimentos',\n",
    "    9: 'hospital'\n",
    "}\n",
    "\n",
    "# Actualizar las nuevas columnas en info_post_df\n",
    "for _, row in caracteristicas_df.iterrows():\n",
    "    archivo = row['filename']\n",
    "    clase = row['clase']\n",
    "    if clase in class_to_cluster:\n",
    "        cluster_id = class_to_cluster[clase]\n",
    "        column_name = cluster_to_column.get(cluster_id, None)\n",
    "        if column_name:\n",
    "            info_post_df.loc[info_post_df['archivo'] == archivo, column_name] = 1\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "info_post_df.to_excel('info_post_prueba_etiquetas.xlsx', index=False)\n",
    "print('Archivo info_post_prueba_etiquetas.xlsx generado exitosamente.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPCION 2. ETIQUETAS ANALIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = 'C:\\\\TFG\\\\imagenes_sin_texto'\n",
    "im_sin_texto = [os.path.splitext(f)[0] for f in os.listdir(directorio) if f.endswith('.jpg')]\n",
    "\n",
    "print(len(im_sin_texto))\n",
    "\n",
    "df = pd.read_excel('C:\\\\TFG\\\\info_post.xlsx')\n",
    "df_filtrado = df[df['archivo'].isin(im_sin_texto)]\n",
    "df_filtrado.to_excel('C:\\\\TFG\\\\info_post_sin_texto.xlsx', index = False, engine = 'openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para mapear las etiquetas a sus clases\n",
    "etiquetas = {'escenario': 'stage',\n",
    "             'microfono': 'microphone',\n",
    "             'instrumento_percusion': ['gong', 'marimba', 'drum', 'drumstick', 'maraca'],\n",
    "             'instrumento_cuerda': ['electric_guitar', 'acoustic_guitar', 'banjo', 'violin', 'cello', 'grand_piano', 'harp', 'organ'],\n",
    "             'instrumento_viento': ['panpipe', 'sax', 'flute', 'basson', 'oboe', 'accordion', 'harmonica', 'cornet', 'trombone', 'ocarina'], \n",
    "             'mascota': ['toy_poodle', 'vizsla', 'miniature_poodle', 'Chihuahua', 'standard_poodle', 'Weimaraner', 'Sussex_spaniel', 'Great_Dane', 'Labrador_retriever', \n",
    "                         'German_shepherd', 'Yorkshire_terrier', 'miniature_pinscher', 'schipperke', 'American_Staffordshire_terrier', 'golden_retriever', 'cocker_spaniel', \n",
    "                         'Dandie_Dinmont', 'giant_schnauzer', 'llama', 'whippet', 'Afghan_hound', 'pug', 'Scottish_deerhound', 'Brittany_spaniel', 'Doberman', 'Pekinese', \n",
    "                         'bloodhound', 'Great_Pyrenees', 'basenji', 'basset', 'beagle', 'Irish_wolfhound', 'Pomeranian', 'Samoyed', 'Siamese_cat', 'kelpie', 'miniature_schnauzer',\n",
    "                         'Rhodesian_ridgeback', 'Siberian_husky', 'tabby', 'dalmatian', 'malamute', 'Sealyham_terrier', 'bull_mastiff', 'Rottweiler', 'Tibetan_mastiff', 'boxer',\n",
    "                         'silky_terrier', ' keeshond', 'Norfolk_terrier', 'Tibetan_terrier', 'Bernese_mountain_dog', 'papillon', 'Border_collie', 'collie', 'Shetland_sheepdog']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_post_df = pd.read_excel('info_post_sin_texto.xlsx')\n",
    "caracteristicas_df = pd.read_excel('caracteristicas.xlsx')\n",
    "\n",
    "# Definir las nuevas columnas\n",
    "new_columns = ['escenario', 'microfono', 'instrumento_percusion', 'instrumento_cuerda', 'instrumento_viento', 'mascota']\n",
    "for col in new_columns:\n",
    "    info_post_df[col] = 0\n",
    "\n",
    "# Actualizar las nuevas columnas en info_post_df\n",
    "for _, row in caracteristicas_df.iterrows():\n",
    "    archivo = row['filename']\n",
    "    print(archivo)\n",
    "    clase = row['clase']\n",
    "    print(clase)\n",
    "    for etiqueta, palabras in etiquetas.items():\n",
    "        if clase in palabras:\n",
    "            info_post_df.loc[info_post_df['archivo'] == archivo, etiqueta] = 1\n",
    "            print(etiqueta)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "info_post_df.to_excel('info_post_sin_texto_etiquetas.xlsx', index=False)\n",
    "\n",
    "print('Archivo info_post_etiquetas.xlsx generado exitosamente.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
